import streamlit as st
import pandas as pd
from fpdf import FPDF
from fpdf.enums import XPos, YPos
import os
from datetime import datetime
import io

# --- 0. ç‰ˆæœ¬å· ---
VERSION = "v1.3.1"

# --- 1. åŸºç¡€å·¥å…·å‡½æ•° (å®Œå…¨ä¸åŠ¨) ---
def get_densities(temp):
    """æ ¹æ®æ¸©åº¦è¾“å‡ºçº¯æ°´å’Œç”Ÿç†ç›æ°´(0.9% NaCl)çš„å¯†åº¦ (g/cm3)"""
    rho_water = 1000 * (1 - (temp + 288.9414) / (508929.2 * (temp + 68.12963)) * (temp - 3.9863)**2)
    rho_water_g = round(rho_water / 1000, 5)
    rho_saline_g = round(rho_water_g * 1.0064, 4) 
    return rho_water_g, rho_saline_g

def calc_theoretical_masses(tc, tm, c_h, rho_h, c_l, rho_l):
    """è®¡ç®—ç†è®ºè´¨é‡ï¼Œç¡®ä¿éè´Ÿ [0, tm]"""
    if tc >= c_h: return tm, 0.0
    if tc <= c_l: return 0.0, tm
    k1 = (c_h - tc) / rho_h
    k2 = (tc - c_l) / rho_l
    if (k1 + k2) == 0: return 0.0, tm
    m_h = (tm * k2) / (k1 + k2)
    m_h = max(0.0, min(float(m_h), float(tm)))
    return m_h, tm - m_h

def calc_actual_volume_conc(m_h, m_l, c_h, rho_h, c_l, rho_l):
    """å›ç®—å®é™…ä½“ç§¯æµ“åº¦"""
    v_h = m_h / rho_h
    v_l = m_l / rho_l
    if (v_h + v_l) == 0: return 0.0
    return (v_h * c_h + v_l * c_l) / (v_h + v_l)

# --- 2. PDF ç”Ÿæˆç±» (å¸¦é¡µè„š) ---
class PDFWithFooter(FPDF):
    def __init__(self, version, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.version = version

    def footer(self):
        self.set_y(-15)
        # --- ä¿®æ”¹1ï¼šç§»é™¤é‡å¤çš„ add_fontï¼Œç›´æ¥ä½¿ç”¨ set_font ---
        # å­—ä½“å·²ç»åœ¨ create_pdf ä¸­è¢«æ·»åŠ ï¼Œè¿™é‡Œåªéœ€æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§æ¥å†³å®šæ˜¯å¦ä½¿ç”¨
        current_dir = os.path.dirname(os.path.abspath(__file__))
        font_path = os.path.join(current_dir, "font.ttf")
        
        if os.path.exists(font_path): 
            # å‡è®¾å¤–éƒ¨å·²æ³¨å†Œåä¸º 'Font'
            self.set_font('Font', '', 8)
        else: 
            self.set_font('Arial', 'I', 8)
            
        self.set_text_color(150, 150, 150)
        
        # ç‰ˆæœ¬ä¿¡æ¯
        if os.path.exists(font_path):
            version_text = f"ç‰ˆæœ¬: {self.version} | ç¨‹åºåˆ›å»ºè€…ï¼šRong"
        else:
            version_text = f"Version: {self.version} | Creator: Rong"
            
        self.cell(0, 10, text=version_text, align='R')
        self.set_y(-15)
        
        # é¡µç ä¿¡æ¯
        if os.path.exists(font_path):
            page_num_text = f"ç¬¬ {self.page_no()} é¡µ"
        else:
            page_num_text = f"Page {self.page_no()}"
            
        self.cell(0, 10, text=page_num_text, align='L')

def create_pdf(df_main, df_mid, title, meta_info):
    version = meta_info.pop("ç¨‹åºç‰ˆæœ¬", "N/A")
    pdf = PDFWithFooter(version=version)
    
    # --- ä¿®æ”¹2ï¼šè®¾ç½®é¡µè¾¹è· (å·¦=25mm, ä¸Š=20mm, å³=20mm) ---
    # é»˜è®¤æ˜¯10mmã€‚å·¦è¾¹è·å¢å¤§2.5å€ -> 25mmï¼Œå³è¾¹è·å¢å¤§1å€(é€šå¸¸æŒ‡ç¿»å€) -> 20mm
    pdf.set_margins(left=25, top=20, right=20)
    
    pdf.add_page()
    
    # å­—ä½“åŠ è½½é€»è¾‘
    current_dir = os.path.dirname(os.path.abspath(__file__))
    font_path = os.path.join(current_dir, "font.ttf")
    font_ok = False
    
    if os.path.exists(font_path):
        pdf.add_font('Font', '', font_path) # åœ¨è¿™é‡Œæ³¨å†Œä¸€æ¬¡å³å¯
        pdf.set_font('Font', size=16)
        font_ok = True
    else: 
        pdf.set_font('Arial', size=16)
        pdf.set_text_color(255, 0, 0)
        pdf.cell(0, 10, text="Warning: font.ttf not found.", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_text_color(0, 0, 0)

    # 1. æ ‡é¢˜ (å®½åº¦è®¾ä¸º0è¡¨ç¤ºåˆ©ç”¨å‰©ä½™å®½åº¦ï¼Œalign='C'ä¼šè‡ªåŠ¨åœ¨marginä¹‹é—´å±…ä¸­)
    display_title = title if font_ok else "Linear Dilution Report"
    pdf.cell(0, 10, text=display_title, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='C')
    pdf.ln(5)
    
    # 2. å…ƒæ•°æ®
    if font_ok: pdf.set_font('Font', size=10)
    else: pdf.set_font('Arial', size=10)
    
    # è®¡ç®—æœ‰æ•ˆå®½åº¦ï¼šA4å®½(210) - å·¦è¾¹è·(15) - å³è¾¹è·(20) = 175
    effective_page_width = pdf.w - pdf.l_margin - pdf.r_margin
    col_width_meta = effective_page_width / 2
    
    items = list(meta_info.items())
    for i in range(0, len(items), 2):
        k1, v1 = items[i]
        if not font_ok: k1 = "Item"; v1 = str(v1).encode('ascii', 'ignore').decode('ascii')
        pdf.cell(col_width_meta, 8, text=f"{k1}: {v1}", new_x=XPos.RIGHT, new_y=YPos.TOP)
        
        if i + 1 < len(items):
            k2, v2 = items[i+1]
            if not font_ok: k2 = "Item"; v2 = str(v2).encode('ascii', 'ignore').decode('ascii')
            pdf.cell(col_width_meta, 8, text=f"{k2}: {v2}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        else: pdf.ln(8)
        
    pdf.ln(4)
    # ç”»çº¿ï¼šä»å·¦è¾¹è·å¼€å§‹ï¼Œåˆ° (é¡µå®½-å³è¾¹è·) ç»“æŸ
    pdf.line(pdf.l_margin, pdf.get_y(), pdf.w - pdf.r_margin, pdf.get_y())
    pdf.ln(5)
    
    # 3. ä¸­é—´æµ“åº¦è¡¨
    if font_ok: 
        pdf.set_font('Font', size=11)
        pdf.cell(0, 10, text="ä¸€ã€ä¸­é—´æµ“åº¦é…ç½®è¯¦æƒ…", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font('Font', size=10)
    else: 
        pdf.set_font('Arial', 'B', 11)
        pdf.cell(0, 10, text="1. Intermediate Prep Details", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font('Arial', size=10)
        
    col_width_mid = effective_page_width / len(df_mid.columns)
    pdf.set_fill_color(245, 245, 245)
    for col in df_mid.columns: 
        txt = str(col) if font_ok else "Col"
        pdf.cell(col_width_mid, 8, text=txt, border=1, align='C', fill=True)
    pdf.ln()
    for _, row in df_mid.iterrows():
        for i, item in enumerate(row):
            if isinstance(item, float): val = f"{item:.2f}" if "æµ“åº¦" in df_mid.columns[i] else f"{item:.1f}"
            else: val = str(item)
            if not font_ok: val = str(val).encode('ascii', 'ignore').decode('ascii')
            pdf.cell(col_width_mid, 8, text=val, border=1, align='C')
        pdf.ln()
    pdf.ln(10)
    
    # 4. æ¢¯åº¦è¡¨
    if font_ok: 
        pdf.set_font('Font', size=11)
        pdf.cell(0, 10, text="äºŒã€åˆ†æ®µæ¢¯åº¦ç¨€é‡Šæ–¹æ¡ˆ", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font('Font', size=10)
    else: 
        pdf.set_font('Arial', 'B', 11)
        pdf.cell(0, 10, text="2. Gradient Dilution Plan", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font('Arial', size=10)
        
    cols = df_main.columns.tolist()
    col_width = effective_page_width / len(cols)
    pdf.set_fill_color(235, 235, 235)
    for col in cols: 
        txt = str(col) if font_ok else "Col"
        pdf.cell(col_width, 10, text=txt, border=1, align='C', fill=True)
    pdf.ln()
    for _, row in df_main.iterrows():
        for i, item in enumerate(row):
            if i == 0: val = str(int(item))
            elif isinstance(item, (int, float)):
                if "æµ“åº¦" in cols[i]: val = f"{item:.2f}"
                else: val = f"{item:.1f}"
            else: val = str(item)
            if not font_ok: val = str(val).encode('ascii', 'ignore').decode('ascii')
            pdf.cell(col_width, 10, text=val, border=1, align='C')
        pdf.ln()
    return pdf.output()

# --- 3. ç•Œé¢åˆå§‹åŒ– ---
st.set_page_config(page_title="çº¿æ€§è¯„ä»·æ ·æœ¬åˆ¶å¤‡ç¨‹åº", layout="wide")

# CSS: 1. å¢åŠ å·¦ä¾§æ å®½åº¦; 2. ç§»é™¤ä¸»ç•Œé¢é¡¶éƒ¨çš„å·¨å¤§ç•™ç©º
st.markdown("""
    <style>
        [data-testid="stSidebar"] { min-width: 500px; max-width: 500px; }
        .block-container { padding-top: 1.5rem; }
        h4 { margin-top: 0rem !important; margin-bottom: 0.2rem !important; }
    </style>
    """, unsafe_allow_html=True)

# å°†ä¸»æ ‡é¢˜å’Œå°æ ‡é¢˜æ”¾åœ¨åŒä¸€è¡Œï¼Œå¹¶æ§åˆ¶å­—å·
st.markdown("""
    <h2>ğŸ§ª ä½“å¤–è¯Šæ–­çº¿æ€§ææ–™é…åˆ¶ç¨‹åº 
    <span style="font-size: 0.65em; font-weight: normal; color: #666;">â€” é€‚ç”¨ç§°é‡ç¨€é‡Šæ³•</span>
    </h4>
    """, unsafe_allow_html=True)
st.caption(f"ç‰ˆæœ¬: {VERSION}")

# XLSX å¯¼å…¥é€»è¾‘
import_data = {}
with st.sidebar.expander("ğŸ“‚ å¯¼å…¥ XLSX å­˜æ¡£", expanded=False):
    uploaded_file = st.file_uploader("å¯¼å…¥ XLSX å­˜æ¡£", type="xlsx", label_visibility="collapsed")
    if uploaded_file:
        try:
            df_settings = pd.read_excel(uploaded_file, sheet_name="é…ç½®å‚æ•°")
            import_data = dict(zip(df_settings["å‚æ•°"], df_settings["æ•°å€¼"]))
            df_grad_import = pd.read_excel(uploaded_file, sheet_name="æ¢¯åº¦æ–¹æ¡ˆ")
            st.success("å­˜æ¡£å¯¼å…¥æˆåŠŸï¼")
        except Exception as e:
            st.error(f"å¯¼å…¥å¤±è´¥: {e}")

with st.sidebar:
    st.subheader("âš™ï¸ åŸºç¡€è®¾ç½®") 
    current_date_str = datetime.now().strftime("%Y%m%d")
    final_exp_name = import_data.get("å®éªŒå†…å®¹")
    if not final_exp_name and uploaded_file: final_exp_name = os.path.splitext(uploaded_file.name)[0]
    if not final_exp_name: final_exp_name = f"çº¿æ€§ç¨€é‡Šå®éªŒ-{current_date_str}"
    exp_name = st.text_input("å®éªŒå†…å®¹åç§°", value=str(final_exp_name))
    
    c_u1, c_u2 = st.columns(2)
    unit_conc = c_u1.text_input("æµ“åº¦å•ä½", value=import_data.get("æµ“åº¦å•ä½", "mg/L"))
    unit_mass = c_u2.text_input("è´¨é‡å•ä½", value=import_data.get("è´¨é‡å•ä½", "mg"))
    
    input_temp = st.number_input("ç¯å¢ƒæ¸©åº¦ (Â°C)", value=float(import_data.get("ç¯å¢ƒæ¸©åº¦", 22.0)), step=0.5)
    rho_w, rho_s = get_densities(input_temp)
    c_d1, c_d2 = st.columns(2)
    c_d1.write(f"ğŸ’§ **çº¯æ°´å¯†åº¦**: `{rho_w}`"); c_d2.write(f"ğŸ¥ **ç”Ÿç†ç›æ°´**: `{rho_s}`")
    
    st.markdown("### ææ–™å‚æ•°")
    c_p1, c_p2 = st.columns(2)
    c_h_orig = c_p1.number_input(f"é«˜æµ“åº¦ææ–™æµ“åº¦", value=float(import_data.get("åŸæ¶²æµ“åº¦A", 100.0)))
    rho_h_orig = c_p2.number_input("é«˜æµ“åº¦ææ–™å¯†åº¦ (g/cm3)", value=float(import_data.get("åŸæ¶²å¯†åº¦A", 1.0500)), format="%.4f")
    c_p3, c_p4 = st.columns(2)
    c_l_orig = c_p3.number_input(f"ä½æµ“åº¦ææ–™æµ“åº¦", value=float(import_data.get("åŸæ¶²æµ“åº¦B", 0.0)))
    rho_l_orig = c_p4.number_input("ä½æµ“åº¦ææ–™å¯†åº¦ (g/cm3)", value=float(import_data.get("åŸæ¶²å¯†åº¦B", 1.0000)), format="%.4f")

    c_p5, c_p6 = st.columns(2)
    num_points = c_p5.number_input("ç¨€é‡Šç‚¹æ•°é‡ (å«ç«¯ç‚¹)", min_value=3, max_value=20, value=int(import_data.get("æ ·æœ¬ç‚¹æ•°", 8)), step=1)
    target_tm_each = c_p6.number_input(f"å„æ¢¯åº¦ç‚¹é…ç½®é‡ ({unit_mass})", value=float(import_data.get("å•ç‚¹è®¡åˆ’æ€»é‡",350)), step=5.0)

# --- 4. é¢„è®¡ç®—ä¸­é—´æµ“åº¦ (å®Œå…¨ä¸åŠ¨) ---
target_c_mid_guess = round((c_h_orig + c_l_orig)/2, 2)
mid_idx_guess = num_points // 2
pts_low_temp = [c_l_orig + i * ((target_c_mid_guess - c_l_orig) / mid_idx_guess) for i in range(mid_idx_guess)]
pts_high_temp = [target_c_mid_guess + i * ((c_h_orig - target_c_mid_guess) / (num_points - mid_idx_guess - 1)) for i in range(num_points - mid_idx_guess)]
all_targets_temp = pts_low_temp + pts_high_temp
total_mid_usage_theo = 0.0
for t_conc in all_targets_temp:
    if t_conc > target_c_mid_guess + 0.0001: _, m_mid_needed = calc_theoretical_masses(t_conc, target_tm_each, c_h_orig, rho_h_orig, target_c_mid_guess, 1.0)
    else: m_mid_needed, _ = calc_theoretical_masses(t_conc, target_tm_each, target_c_mid_guess, 1.0, c_l_orig, rho_l_orig)
    total_mid_usage_theo += m_mid_needed
suggested_prep_m = round(total_mid_usage_theo * 1.1, 1)

# --- 5. æ­¥éª¤ä¸€ï¼šä¸­é—´é…ç½® (é™æ¡£æ ‡é¢˜ + å¹¶åˆ—å¸ƒå±€) ---
st.markdown("#### 1ï¸âƒ£ ä¸­é—´æµ“åº¦é…ç½®") # æ ‡é¢˜ç¼©å°ä¸€æ¡£
with st.container(border=True):
    col_left, col_right = st.columns(2)
    with col_left:
        target_c_mid = st.number_input(f"ä¸­é—´ç›®æ ‡æµ“åº¦ ({unit_conc})", value=float(import_data.get("ä¸­é—´ç›®æ ‡æµ“åº¦", target_c_mid_guess)), step=0.1)
        prep_m_mid = st.number_input(f"é…ç½®æ€»è´¨é‡ (å»ºè®®: æ€»éœ€æ±‚Ã—1.1)", value=float(import_data.get("ä¸­é—´è®¡åˆ’æ€»é‡", max(suggested_prep_m, 100.0))), step=10.0)
        m_h_theo, m_l_theo = calc_theoretical_masses(target_c_mid, prep_m_mid, c_h_orig, rho_h_orig, c_l_orig, rho_l_orig)
        st.info(f"ğŸ’¡ å»ºè®®ï¼šé«˜æµ“åº¦ææ–™ {m_h_theo:.1f} + ä½æµ“åº¦ææ–™ {m_l_theo:.1f} (ç†è®ºç”¨é‡å’Œ: {total_mid_usage_theo:.1f})")
    with col_right:
        m_h_mid_act = st.number_input("åŠ å…¥é«˜æµ“åº¦ææ–™ (å®æµ‹è´¨é‡)", value=float(import_data.get("ä¸­é—´å®æµ‹A", round(m_h_theo, 1))), min_value=0.0, step=0.1, format="%.1f", key="mid_h_val")
        m_l_mid_act = st.number_input("åŠ å…¥ä½æµ“åº¦ææ–™ (å®æµ‹è´¨é‡)", value=float(import_data.get("ä¸­é—´å®æµ‹B", round(m_l_theo, 1))), min_value=0.0, step=0.1, format="%.1f", key="mid_l_val")
        actual_c_mid = calc_actual_volume_conc(m_h_mid_act, m_l_mid_act, c_h_orig, rho_h_orig, c_l_orig, rho_l_orig)
        denom = (m_h_mid_act/rho_h_orig) + (m_l_mid_act/rho_l_orig)
        actual_rho_mid = (m_h_mid_act + m_l_mid_act) / denom if denom > 0 else 1.0
        st.warning(f"ğŸ§ª **ä¸­é—´æµ“åº¦å®é™…å‚æ•°**ï¼šæµ“åº¦ **{actual_c_mid:.2f}**ï¼Œå¯†åº¦ **{actual_rho_mid:.4f}**")

# --- 6. æ­¥éª¤äºŒï¼šåˆ†æ®µæ¢¯åº¦ç¨€é‡Šæ–¹æ¡ˆ (é™æ¡£æ ‡é¢˜ + å­—ä½“å¤§å°ä¸€è‡´) ---
st.markdown("#### 2ï¸âƒ£ åˆ†æ®µæ¢¯åº¦ç¨€é‡Šæ–¹æ¡ˆ") # æ ‡é¢˜ç¼©å°ä¸€æ¡£
mid_idx = num_points // 2
pts_low = [c_l_orig + i * ((actual_c_mid - c_l_orig) / mid_idx) for i in range(mid_idx)]
pts_high = [actual_c_mid + i * ((c_h_orig - actual_c_mid) / (num_points - mid_idx - 1)) for i in range(num_points - mid_idx)]
all_targets = pts_low + pts_high
h_cols = st.columns([0.5, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2])
headers = ["åºå·", "ç›®æ ‡æµ“åº¦", "ææ–™A", "ææ–™B", "åŠ å…¥Aè´¨é‡", "åŠ å…¥Bè´¨é‡", "å®é™…æµ“åº¦"]
for col, lab in zip(h_cols, headers): col.write(f"**{lab}**")

results_data = []
total_high_used = m_h_mid_act
total_low_used = m_l_mid_act
for i, t_conc in enumerate(all_targets):
    idx = i + 1
    if t_conc > actual_c_mid + 0.0001: m_a_name, m_b_name, ca, ra, cb, rb = "é«˜æµ“åº¦", "ä¸­é—´æµ“åº¦", c_h_orig, rho_h_orig, actual_c_mid, actual_rho_mid
    else: m_a_name, m_b_name, ca, ra, cb, rb = "ä¸­é—´æµ“åº¦", "ä½æµ“åº¦", actual_c_mid, actual_rho_mid, c_l_orig, rho_l_orig
    imp_tc, imp_ma, imp_mb = t_conc, None, None
    if uploaded_file and 'df_grad_import' in locals():
        if i < len(df_grad_import): imp_tc, imp_ma, imp_mb = df_grad_import.iloc[i]["ç›®æ ‡æµ“åº¦"], df_grad_import.iloc[i]["åŠ å…¥Aè´¨é‡"], df_grad_import.iloc[i]["åŠ å…¥Bè´¨é‡"]
    r_cols = st.columns([0.5, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2])
    r_cols[0].write(f"{idx}")
    row_tc = r_cols[1].number_input(f"tc_{i}", value=float(imp_tc), format="%.2f", key=f"row_tc_{i}", label_visibility="collapsed", step=0.1)
    # ä½¿ç”¨ st.write ç¡®ä¿å­—ä½“å¤§å°ä¸ä¸»ç•Œé¢ä¸€è‡´
    r_cols[2].write(m_a_name); r_cols[3].write(m_b_name)
    m_a_theo_row, m_b_theo_row = calc_theoretical_masses(row_tc, target_tm_each, ca, ra, cb, rb)
    row_ma = r_cols[4].number_input(f"ma_{i}", value=float(imp_ma if imp_ma is not None else round(m_a_theo_row, 1)), min_value=0.0, step=0.1, format="%.1f", key=f"row_ma_{i}", label_visibility="collapsed")
    row_mb = r_cols[5].number_input(f"mb_{i}", value=float(imp_mb if imp_mb is not None else round(m_b_theo_row, 1)), min_value=0.0, step=0.1, format="%.1f", key=f"row_mb_{i}", label_visibility="collapsed")
    row_act_c = calc_actual_volume_conc(row_ma, row_mb, ca, ra, cb, rb)
    r_cols[6].write(f"**{row_act_c:.2f}**")
    results_data.append({"åºå·": idx, "ç›®æ ‡æµ“åº¦": row_tc, "ææ–™A": m_a_name, "ææ–™B": m_b_name, "åŠ å…¥Aè´¨é‡": row_ma, "åŠ å…¥Bè´¨é‡": row_mb, "æœ€ç»ˆå®é™…æµ“åº¦": row_act_c})
    if m_a_name == "é«˜æµ“åº¦": total_high_used += row_ma
    if m_b_name == "ä½æµ“åº¦": total_low_used += row_mb

# --- 7. æ•°æ®å¯¼å‡ºåŒºåŸŸ (å®Œå…¨ä¸åŠ¨) ---
c_x1, c_x2 = st.columns(2)
with c_x1:
    if st.button("ğŸ’¾ å¯¼å‡º XLSX å­˜æ¡£"):
        settings_dict = {
            "ç¨‹åºç‰ˆæœ¬": VERSION, "å®éªŒå†…å®¹": exp_name, "æµ“åº¦å•ä½": unit_conc, "è´¨é‡å•ä½": unit_mass, "ç¯å¢ƒæ¸©åº¦": input_temp,
            "åŸæ¶²æµ“åº¦A": c_h_orig, "åŸæ¶²å¯†åº¦A": rho_h_orig, "åŸæ¶²æµ“åº¦B": c_l_orig, "åŸæ¶²å¯†åº¦B": rho_l_orig,
            "æ ·æœ¬ç‚¹æ•°": num_points, "å•ç‚¹è®¡åˆ’æ€»é‡": target_tm_each, "ä¸­é—´ç›®æ ‡æµ“åº¦": target_c_mid, "ä¸­é—´è®¡åˆ’æ€»é‡": prep_m_mid,
            "ä¸­é—´å®æµ‹A": m_h_mid_act, "ä¸­é—´å®æµ‹B": m_l_mid_act
        }
        df_settings = pd.DataFrame(list(settings_dict.items()), columns=["å‚æ•°", "æ•°å€¼"])
        df_grad = pd.DataFrame(results_data)
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_settings.to_excel(writer, sheet_name="é…ç½®å‚æ•°", index=False)
            df_grad.to_excel(writer, sheet_name="æ¢¯åº¦æ–¹æ¡ˆ", index=False)
        st.download_button("ğŸ“¥ ç‚¹å‡»ä¸‹è½½ XLSX", data=output.getvalue(), file_name=f"{exp_name}_{datetime.now().strftime('%H%M')}.xlsx")
with c_x2:
    if st.button("ğŸ“‘ ç”Ÿæˆå®éªŒ PDF æŠ¥å‘Š"):
        mid_prep_df = pd.DataFrame([
            {"ç»„åˆ†": "é«˜æµ“åº¦ææ–™", "ç†è®ºè´¨é‡": m_h_theo, "åŠ å…¥è´¨é‡": m_h_mid_act, "ç›®æ ‡æµ“åº¦": "-", "å®é™…é…ç½®æµ“åº¦": "-"},
            {"ç»„åˆ†": "ä½æµ“åº¦ææ–™", "ç†è®ºè´¨é‡": m_l_theo, "åŠ å…¥è´¨é‡": m_l_mid_act, "ç›®æ ‡æµ“åº¦": "-", "å®é™…é…ç½®æµ“åº¦": "-"},
            {"ç»„åˆ†": "åˆè®¡(ä¸­é—´æµ“åº¦ææ–™)", "ç†è®ºè´¨é‡": m_h_theo + m_l_theo, "åŠ å…¥è´¨é‡": m_h_mid_act + m_l_mid_act, "ç›®æ ‡æµ“åº¦": target_c_mid, "å®é™…é…ç½®æµ“åº¦": actual_c_mid}
        ])
        mid_prep_df.columns = ["ç»„åˆ†", f"ç†è®ºè´¨é‡({unit_mass})", f"åŠ å…¥è´¨é‡({unit_mass})", f"ç›®æ ‡æµ“åº¦({unit_conc})", f"å®é™…é…ç½®æµ“åº¦({unit_conc})"]
        pdf_meta = {
            "ç¨‹åºç‰ˆæœ¬": VERSION, "å®éªŒå†…å®¹": exp_name, "ç¯å¢ƒæ¸©åº¦": f"{input_temp} degC", "æ°´å¯†åº¦": f"{rho_w} g/cm3",
            "ç”Ÿç†ç›æ°´å¯†åº¦": f"{rho_s} g/cm3", "é«˜æµ“åº¦ææ–™": f"{c_h_orig} {unit_conc} (å¯†åº¦:{rho_h_orig:.4f})",
            "ä½æµ“åº¦ææ–™": f"{c_l_orig} {unit_conc} (å¯†åº¦:{rho_l_orig:.4f})", "ä¸­é—´æµ“åº¦ææ–™": f"{actual_c_mid:.2f} {unit_conc} (å¯†åº¦:{actual_rho_mid:.4f})",
            "é«˜æµ“åº¦ææ–™åˆè®¡é‡": f"{total_high_used:.1f} {unit_mass}", "ä½æµ“åº¦ææ–™åˆè®¡é‡": f"{total_low_used:.1f} {unit_mass}",
            "å¯¼å‡ºæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M")
        }
        pdf_out = create_pdf(pd.DataFrame(results_data), mid_prep_df, "çº¿æ€§è¯„ä»·æ ·æœ¬åˆ¶å¤‡è®°å½•", pdf_meta)
        st.download_button("ğŸ“¥ ç‚¹å‡»ä¸‹è½½ PDF", data=bytes(pdf_out), file_name=f"Report_{exp_name}_{datetime.now().strftime('%H%M')}.pdf", mime="application/pdf")